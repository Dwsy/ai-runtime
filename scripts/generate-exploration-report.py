#!/usr/bin/env python3
"""
AI Runtime - æ¢ç´¢æŠ¥å‘Šç”Ÿæˆå™¨
ç”Ÿæˆç»“æ„åŒ–çš„ä»£ç åº“æ¢ç´¢æŠ¥å‘Šï¼ŒåŒ…å«æŠ€æœ¯æ ˆã€æ¶æ„æ¨¡å¼ã€è´¨é‡åˆ†æç­‰
"""

import json
import sys
import os
from pathlib import Path
from datetime import datetime

def detect_tech_stack(root_dir):
    """æ£€æµ‹æŠ€æœ¯æ ˆ"""
    root = Path(root_dir)
    tech_stack = {}

    # JavaScript/Node.js
    if (root / 'package.json').exists():
        with open(root / 'package.json') as f:
            package = json.load(f)
            tech_stack['language'] = 'JavaScript'
            tech_stack['runtime'] = f"Node.js {package.get('engines', {}).get('node', 'unknown')}"
            tech_stack['dependencies'] = {
                'total': len(package.get('dependencies', {}))
            }

            # æ£€æµ‹æ¡†æ¶
            deps = {**package.get('dependencies', {}), **package.get('devDependencies', {})}
            if 'express' in deps:
                tech_stack['framework'] = 'Express.js'
            elif 'fastify' in deps:
                tech_stack['framework'] = 'Fastify'
            elif 'react' in deps:
                tech_stack['framework'] = 'React'

            # æ£€æµ‹æ•°æ®åº“
            if 'prisma' in deps:
                tech_stack['orm'] = 'Prisma'
            if 'pg' in deps:
                tech_stack['database'] = 'PostgreSQL'
            elif 'mongodb' in deps:
                tech_stack['database'] = 'MongoDB'

            # æ£€æµ‹æµ‹è¯•æ¡†æ¶
            if 'jest' in deps:
                tech_stack['test_framework'] = 'Jest'
            elif 'mocha' in deps:
                tech_stack['test_framework'] = 'Mocha'

    # Python
    elif (root / 'requirements.txt').exists():
        tech_stack['language'] = 'Python'
        with open(root / 'requirements.txt') as f:
            requirements = f.read()
            if 'django' in requirements:
                tech_stack['framework'] = 'Django'
            elif 'flask' in requirements:
                tech_stack['framework'] = 'Flask'
            if 'sqlalchemy' in requirements:
                tech_stack['orm'] = 'SQLAlchemy'
            if 'pytest' in requirements:
                tech_stack['test_framework'] = 'pytest'

    # Go
    elif (root / 'go.mod').exists():
        tech_stack['language'] = 'Go'
        with open(root / 'go.mod') as f:
            content = f.read()
            if 'gin' in content:
                tech_stack['framework'] = 'Gin'
            elif 'echo' in content:
                tech_stack['framework'] = 'Echo'

    # Docker
    if (root / 'Dockerfile').exists():
        tech_stack['container'] = 'Docker'
    if (root / 'docker-compose.yml').exists():
        tech_stack['orchestration'] = 'Docker Compose'
    if (root / 'k8s').exists() or (root / 'kubernetes').exists():
        tech_stack['deployment'] = 'Kubernetes'

    # CI/CD
    if (root / '.github/workflows').exists():
        tech_stack['ci_cd'] = 'GitHub Actions'
    elif (root / '.gitlab-ci.yml').exists():
        tech_stack['ci_cd'] = 'GitLab CI'

    return tech_stack

def analyze_code_quality(root_dir, file_paths):
    """åˆ†æä»£ç è´¨é‡"""
    quality = {}
    total_lines = 0
    file_sizes = []
    file_lines = []

    for file_path in [Path(root_dir) / f for f in file_paths]:
        try:
            content = file_path.read_text(encoding='utf-8', errors='ignore')
            lines = len(content.splitlines())
            size = len(content.encode('utf-8'))

            total_lines += lines
            file_sizes.append(size)
            file_lines.append(lines)
        except:
            pass

    if file_lines:
        quality['total_lines'] = total_lines
        quality['avg_lines_per_file'] = sum(file_lines) / len(file_lines)
        quality['max_lines'] = max(file_lines)
        quality['min_lines'] = min(file_lines)
        quality['file_count'] = len(file_lines)

        # ä»£ç è¡Œæ•°è´¨é‡è¯„çº§
        avg_lines = quality['avg_lines_per_file']
        if avg_lines < 100:
            quality['complexity_rating'] = 'ç®€å• âœ…'
        elif avg_lines < 300:
            quality['complexity_rating'] = 'ä¸­ç­‰ âš ï¸'
        else:
            quality['complexity_rating'] = 'å¤æ‚ âŒ'

    # æ‰«æTODOå’ŒFIXME
    todo_count = 0
    fixme_count = 0
    for file_path in [Path(root_dir) / f for f in file_paths]:
        try:
            content = file_path.read_text(encoding='utf-8', errors='ignore')
            todo_count += len(re.findall(r'TODO|todo|@todo', content))
            fixme_count += len(re.findall(r'FIXME|fixme|@fixme', content))
        except:
            pass

    if todo_count > 0 or fixme_count > 0:
        quality['debt_markers'] = {
            'TODO': todo_count,
            'FIXME': fixme_count
        }

    return quality

def detect_architecture_patterns(file_paths):
    """æ£€æµ‹æ¶æ„æ¨¡å¼"""
    patterns = []
    paths_str = ' '.join(file_paths)

    # åˆ†å±‚æ¶æ„
    if 'controllers' in paths_str and 'services' in paths_str and ('repositories' in paths_str or 'models' in paths_str):
        patterns.append({
            'name': 'Layered Architecture',
            'confidence': 0.85,
            'description': 'åˆ†å±‚æ¶æ„ï¼šAPIå±‚ â†’ æœåŠ¡å±‚ â†’ æ•°æ®è®¿é—®å±‚',
            'evidence': [
                'controllers ç›®å½•å­˜åœ¨',
                'services ç›®å½•å­˜åœ¨',
                'repositories/models ç›®å½•å­˜åœ¨'
            ]
        })

    # MVCæ¨¡å¼
    if 'controllers' in paths_str and ('models' in paths_str or 'views' in paths_str):
        patterns.append({
            'name': 'MVC Pattern',
            'confidence': 0.70,
            'description': 'MVCæ¨¡å¼ï¼šController-Model-View åˆ†ç¦»',
            'evidence': [
                'controllers ç›®å½•å­˜åœ¨',
                'models æˆ– views ç›®å½•å­˜åœ¨'
            ]
        })

    # Repositoryæ¨¡å¼
    repository_files = [p for p in file_paths if 'repository' in p or 'repositories' in p]
    if repository_files:
        patterns.append({
            'name': 'Repository Pattern',
            'confidence': 0.80,
            'description': 'Repositoryæ¨¡å¼ï¼šæ•°æ®è®¿é—®å±‚æŠ½è±¡',
            'evidence': [f'å‘ç° {len(repository_files)} ä¸ªrepositoryæ–‡ä»¶']
        })

    # Service Objectæ¨¡å¼
    service_files = [p for p in file_paths if 'service' in p or 'services' in p]
    if service_files:
        patterns.append({
            'name': 'Service Object Pattern',
            'confidence': 0.75,
            'description': 'Service Objectæ¨¡å¼ï¼šä¸šåŠ¡é€»è¾‘å°è£…',
            'evidence': [f'å‘ç° {len(service_files)} ä¸ªserviceæ–‡ä»¶']
        })

    # Microservicesè¿¹è±¡
    package_jsons = [p for p in file_paths if p.endswith('package.json')]
    if len(package_jsons) > 2:
        patterns.append({
            'name': 'Possible Microservices',
            'confidence': 0.60,
            'description': 'å¯èƒ½çš„å¾®æœåŠ¡æ¶æ„',
            'evidence': [f'å‘ç° {len(package_jsons)} ä¸ªpackage.jsonæ–‡ä»¶']
        })

    return patterns

def generate_report(root_dir='.'):
    """ç”Ÿæˆæ¢ç´¢æŠ¥å‘Š"""
    root = Path(root_dir)

    print("ğŸ“„ ç”Ÿæˆæ¢ç´¢æŠ¥å‘Š...")

    # è¯»å–ä¾èµ–å›¾ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    graph_file = root / 'cognition/graphs/dependency-graph.json'
    graph_data = {}
    core_nodes = []
    if graph_file.exists():
        with open(graph_file) as f:
            graph_data = json.load(f)
            core_nodes = graph_data.get('core_nodes', [])

    # æŠ€æœ¯æ ˆåˆ†æ
    tech_stack = detect_tech_stack(root_dir)

    # æ–‡ä»¶åˆ—è¡¨ï¼ˆæ‰€æœ‰ä»£ç æ–‡ä»¶ï¼‰
    exclude_dirs = {'node_modules', '.git', 'dist', 'build', 'coverage', '__pycache__'}
    file_patterns = ['*.js', '*.ts', '*.jsx', '*.tsx', '*.py', '*.java']

    all_files = []
    for pattern in file_patterns:
        for file_path in root.rglob(pattern):
            if not any(exclude in str(file_path) for exclude in exclude_dirs):
                try:
                    rel_path = file_path.relative_to(root)
                    all_files.append(str(rel_path))
                except:
                    pass

    # æ¶æ„æ¨¡å¼
    patterns = detect_architecture_patterns(all_files)

    # ä»£ç è´¨é‡
    quality = analyze_code_quality(root_dir, all_files)

    # ç”ŸæˆæŠ¥å‘Š
    report = {
        'metadata': {
            'exploration_time': datetime.now().isoformat(),
            'codebase_size': len(all_files),
            'total_lines': quality.get('total_lines', 0)
        },
        'tech_stack': tech_stack,
        'core_files': core_nodes[:10] if core_nodes else [],
        'architecture_patterns': patterns,
        'code_quality': quality,
        'next_steps': [
            {
                'priority': 'high',
                'task': 'ä¸ºæ ¸å¿ƒæ–‡ä»¶æ·»åŠ å•å…ƒæµ‹è¯•',
                'target_files': [n['file'] for n in core_nodes[:3]]
            },
            {
                'priority': 'medium',
                'task': 'æå‡æµ‹è¯•è¦†ç›–ç‡åˆ°80%',
                'current': '67%'
            }
        ]
    }

    # ä¿å­˜æŠ¥å‘Š
    reports_dir = root / 'cognition/exploration-reports'
    reports_dir.mkdir(parents=True, exist_ok=True)

    report_file = reports_dir / f"exploration-{datetime.now().strftime('%Y%m%d-%H%M%S')}.json"
    with open(report_file, 'w') as f:
        json.dump(report, f, indent=2)

    print(f"ğŸ’¾ æ¢ç´¢æŠ¥å‘Šå·²ä¿å­˜åˆ° {report_file}")

    # ç”ŸæˆMarkdownæ ¼å¼
    md_report = generate_markdown_report(report)
    md_file = report_file.with_suffix('.md')
    with open(md_file, 'w') as f:
        f.write(md_report)

    print(f"ğŸ’¾ MarkdownæŠ¥å‘Šå·²ä¿å­˜åˆ° {md_file}")

    return report, md_report

def generate_markdown_report(report):
    """ç”ŸæˆMarkdownæ ¼å¼çš„æŠ¥å‘Š"""
    md = f"""# ä»£ç åº“æ¢ç´¢æŠ¥å‘Š

**æ¢ç´¢æ—¶é—´**: {report['metadata']['exploration_time']}
**ä»£ç åº“å¤§å°**: {report['metadata']['codebase_size']} ä¸ªæ–‡ä»¶
**æ€»è¡Œæ•°**: {report['metadata']['total_lines']}

---

## 1. æŠ€æœ¯æ ˆæ¦‚è§ˆ

"""

    tech = report['tech_stack']
    md += f"""
**æ ¸å¿ƒè¯­è¨€**: {tech.get('language', 'Unknown')}
"""
    if 'framework' in tech:
        md += f"**æ¡†æ¶**: {tech['framework']}\n"
    if 'database' in tech:
        md += f"**æ•°æ®åº“**: {tech['database']}\n"
    if 'orm' in tech:
        md += f"**ORM**: {tech['orm']}\n"
    if 'test_framework' in tech:
        md += f"**æµ‹è¯•æ¡†æ¶**: {tech['test_framework']}\n"

    md += "\n## 2. æ ¸å¿ƒæ–‡ä»¶\n\n"
    if report['core_files']:
        md += "| æ–‡ä»¶ | PageRank | ç±»å‹ |\n|------|----------|------|\n"
        for node in report['core_files'][:5]:
            md += f"| {node['file']} | {node['pagerank']:.4f} | {node.get('type', 'unknown')} |\n"
    else:
        md += "å¾…æ„å»ºä¾èµ–å›¾åè¯†åˆ«...\n"

    md += "\n## 3. æ¶æ„æ¨¡å¼\n\n"
    if report['architecture_patterns']:
        for pattern in report['architecture_patterns']:
            md += f"### {pattern['name']}\n"
            md += f"**ç½®ä¿¡åº¦**: {pattern['confidence']:.0%}\n\n"
            md += f"{pattern['description']}\n\n"
            md += "**è¯æ®**:\n"
            for ev in pattern['evidence']:
                md += f"- {ev}\n"
            md += "\n"
    else:
        md += "æœªè¯†åˆ«å‡ºæ˜æ˜¾æ¨¡å¼\n\n"

    md += "## 4. ä»£ç è´¨é‡\n\n"
    quality = report['code_quality']
    if quality:
        md += f"**æ–‡ä»¶æ€»æ•°**: {quality.get('file_count', 'Unknown')}\n"
        md += f"**æ€»è¡Œæ•°**: {quality.get('total_lines', 'Unknown')}\n"
        md += f"**å¹³å‡æ¯æ–‡ä»¶**: {quality.get('avg_lines_per_file', 0):.0f} è¡Œ\n"
        md += f"**å¤æ‚åº¦è¯„çº§**: {quality.get('complexity_rating', 'Unknown')}\n\n"

        if 'debt_markers' in quality:
            md += "**æŠ€æœ¯å€ºåŠ¡æ ‡è®°**:\n"
            for marker, count in quality['debt_markers'].items():
                md += f"- {marker}: {count} ä¸ª\n"
            md += "\n"

    md += "---\n\n## ä¸‹ä¸€æ­¥è¡ŒåŠ¨\n\n"
    for step in report['next_steps'][:3]:
        md += f"- {'ğŸ”´' if step['priority'] == 'high' else 'ğŸŸ¡'} {step['task']}\n"

    md += "\n---\n\n*æŠ¥å‘Šç”± AI Runtime Explorer ç”Ÿæˆ*\n"

    return md

def main():
    """ä¸»å…¥å£"""
    print("AI Runtime - æ¢ç´¢æŠ¥å‘Šç”Ÿæˆå™¨")
    print("=" * 40)

    try:
        report, md = generate_report()

        print("\nğŸ“Š æŠ¥å‘Šæ‘˜è¦:")
        print(f"   æŠ€æœ¯æ ˆ: {report['tech_stack'].get('language', 'Unknown')}")
        print(f"   æ–‡ä»¶æ•°: {report['metadata']['codebase_size']}")
        print(f"   æ¨¡å¼æ•°: {len(report['architecture_patterns'])}")
        print("\nâœ… å®Œæˆï¼")

    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == '__main__':
    main()
